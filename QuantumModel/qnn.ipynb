{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sS9JG4Tjw_Zt"
      },
      "outputs": [],
      "source": [
        "# pip install matplotlib qiskit qiskit_aer qiskit_algorithms qiskit_machine_learning seaborn scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "IdOoatFErhYm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, MultiLabelBinarizer, OrdinalEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap, EfficientSU2\n",
        "from qiskit_aer import AerSimulator\n",
        "from qiskit.primitives import StatevectorEstimator\n",
        "from qiskit_algorithms.optimizers import SPSA, COBYLA\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "from qiskit_machine_learning.algorithms.regressors import NeuralNetworkRegressor\n",
        "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rdsskxctLyp",
        "outputId": "5c896424-1602-4ed4-d4ac-2a92f0682ea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Quantum Machine Learning for Egyptian Archaeological Dataset ===\n",
            "\n",
            "Loading dataset...\n",
            "Dataset shape: (500, 11)\n",
            "Columns: ['Site ID', 'Latitude', 'Longitude', 'Time Period', 'Material Composition', 'Script Detected', 'AI Prediction Score', 'Human Activity Index', 'Climate Change Impact', 'Sonar Radar Detection', 'Looting Risk (%)']\n",
            "Features selected: ['Human Activity Index', 'Climate Change Impact', 'Sonar Radar Detection', 'Looting Risk (%)', 'Period_Encoded', 'Script_encoded']\n"
          ]
        }
      ],
      "source": [
        "print(\"=== Quantum Machine Learning for Egyptian Archaeological Dataset ===\\n\")\n",
        "\n",
        "\n",
        "print(\"Loading dataset...\")\n",
        "file_path = '../dataset.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "# 1. Time Period Encoding (Ordinal)\n",
        "ordinal_order = [\n",
        "    \"Antiguo Reino\",\n",
        "    \"Primer Período Intermedio\",\n",
        "    \"Imperio Medio\",\n",
        "    \"Segundo Período Intermedio\",\n",
        "    \"Imperio Nuevo\",\n",
        "    \"Tercer Período Intermedio\",\n",
        "    \"Periodo Tardío\",\n",
        "    \"Periodo Ptolemaico\",\n",
        "    \"Periodo Romano\"\n",
        "]\n",
        "encoder = OrdinalEncoder(categories=[ordinal_order])\n",
        "df['Period_Encoded'] = encoder.fit_transform(df[['Time Period']])\n",
        "\n",
        "# 2. Script Detected Encoding (Value-based mapping)\n",
        "scripts = {\n",
        "    'Demótico': 0.9,\n",
        "    'Cuneiforme':0.6,\n",
        "    'Hierático': 0.85,\n",
        "    'Griego': 0.7,\n",
        "    'Copto': 0.8,\n",
        "    'Jeroglífico': 1.0,\n",
        "}\n",
        "df['Script_encoded'] = df[\"Script Detected\"].map(scripts)\n",
        "\n",
        "# 3. Material Composition Multi-hot Encoding\n",
        "df[\"Material Composition\"] = df[\"Material Composition\"].fillna(\"\")\n",
        "material_lists = df[\"Material Composition\"].str.lower().str.strip().str.split(r\",\\s*\")\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "multi_hot = mlb.fit_transform(material_lists)\n",
        "multi_hot_df = pd.DataFrame(multi_hot, columns=mlb.classes_, index=df.index)\n",
        "df = pd.concat([df, multi_hot_df], axis=1)\n",
        "\n",
        "# 4. Location Clustering\n",
        "coords = df[['Longitude', 'Latitude']].dropna()\n",
        "kmeans = KMeans(n_clusters=4, random_state=42)\n",
        "df['LocationCluster'] = kmeans.fit_predict(coords)\n",
        "\n",
        "print(\"Data preprocessing completed!\")\n",
        "print(f\"Final dataset shape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg0drNQ_rjte",
        "outputId": "3aaf84eb-d0f9-4e8c-a2a9-9195f0c799ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Splitting data into train/test sets...\n",
            "Scaling features...\n"
          ]
        }
      ],
      "source": [
        "# Split the data\n",
        "print(\"\\nSplitting data into train/test sets...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=10\n",
        ")\n",
        "\n",
        "# Separate scalers for features and target\n",
        "print(\"Scaling features...\")\n",
        "feature_scaler = StandardScaler()\n",
        "target_scaler = StandardScaler()\n",
        "\n",
        "# Scale features\n",
        "X_train_scaled = feature_scaler.fit_transform(X_train)\n",
        "X_test_scaled = feature_scaler.transform(X_test)\n",
        "\n",
        "# Scale target (reshape if 1D)\n",
        "y_train_scaled = target_scaler.fit_transform(y_train.reshape(-1, 1))\n",
        "y_test_scaled = target_scaler.transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# Flatten target again\n",
        "Y_train_scaled = y_train_scaled.flatten()\n",
        "Y_test_scaled = y_test_scaled.flatten()\n",
        "\n",
        "\n",
        "# For quantum ML, we need to limit the number of features due to computational constraints\n",
        "# Select the most important features (first 6)\n",
        "n_quantum_features = min(6, X_train_scaled.shape[1])\n",
        "X_train_quantum = X_train_scaled[:, :n_quantum_features]\n",
        "X_test_quantum = X_test_scaled[:, :n_quantum_features]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVLQfvtLud-m",
        "outputId": "8039a55f-976f-4150-e8f9-87dda5899a30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Quantum Neural Network...\n",
            "Creating QNN with 6 qubits for 6 features\n",
            "Training quantum model...\n",
            "This may take several minutes...\n",
            "Training completed!\n"
          ]
        }
      ],
      "source": [
        "# Train quantum model\n",
        "print(\"Creating Quantum Neural Network...\")\n",
        "\n",
        "print(f\"Creating QNN with {6} qubits for {n_quantum_features} features\")\n",
        "\n",
        "# Create quantum circuits\n",
        "feature_map = ZZFeatureMap(feature_dimension=n_quantum_features, reps=2, entanglement='linear')\n",
        "ansatz = EfficientSU2(6, reps=2, entanglement='linear')\n",
        "\n",
        "# Create the complete circuit\n",
        "qc = QuantumCircuit(6)\n",
        "qc.compose(feature_map, inplace=True)\n",
        "qc.compose(ansatz, inplace=True)\n",
        "\n",
        "# Set up the estimator\n",
        "estimator = StatevectorEstimator()\n",
        "\n",
        "\n",
        "pass_manager = generate_preset_pass_manager(optimization_level=2)\n",
        "\n",
        "# Create observable (Pauli-Z measurement on first qubit)\n",
        "observable = SparsePauliOp.from_list([(\"Z\" + \"I\" * (6-1), 1.0)])\n",
        "\n",
        "# Create QNN\n",
        "qnn = EstimatorQNN(\n",
        "    circuit=qc,\n",
        "    observables=observable,\n",
        "    input_params=feature_map.parameters,\n",
        "    weight_params=ansatz.parameters,\n",
        "    estimator=estimator,\n",
        "    gradient=None,\n",
        "    pass_manager=pass_manager\n",
        ")\n",
        "\n",
        "# Set up optimizer\n",
        "optimizer = SPSA(maxiter=150)  # Reduced iterations for faster training\n",
        "\n",
        "# Create quantum regressor\n",
        "qnn_regressor = NeuralNetworkRegressor(\n",
        "    neural_network=qnn,\n",
        "    optimizer=optimizer,\n",
        "    loss='absolute_error'\n",
        ")\n",
        "\n",
        "print(\"Training quantum model...\")\n",
        "print(\"This may take several minutes...\")\n",
        "\n",
        "# Fit the model\n",
        "qnn_regressor.fit(X_train_quantum, Y_train_scaled)\n",
        "\n",
        "print(\"Training completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7eWdfUQvTrF",
        "outputId": "0047c60a-b09b-42b5-c55c-a7bb58924447"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Root Mean Square Error (RMSE): 0.9675\n",
            "Mean Absolute Error (MAE): 0.8505\n",
            "R² Score: -0.0256\n",
            "\n",
            "=== Analysis Complete ===\n"
          ]
        }
      ],
      "source": [
        "# Make predictions\n",
        "y_pred = qnn_regressor.predict(X_test_quantum)\n",
        "\n",
        "# Calculate metrics\n",
        "mse = mean_squared_error(Y_test_scaled, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(Y_test_scaled, y_pred)\n",
        "r2 = r2_score(Y_test_scaled, y_pred)\n",
        "\n",
        "print(f\"Root Mean Square Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"R² Score: {r2:.4f}\")\n",
        "\n",
        "print(\"\\n=== Analysis Complete ===\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kx-pA3OlrMay"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
